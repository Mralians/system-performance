<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>system-performance</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = null;
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="linux_60-Second_analysis.html"><strong aria-hidden="true">1.</strong> Linux 60 Second Analysis</a></li><li class="chapter-item expanded "><a href="bpftrace.html"><strong aria-hidden="true">2.</strong> Bpftrace one-line commands</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="bpftrace/cpu.html"><strong aria-hidden="true">2.1.</strong> CPU</a></li><li class="chapter-item expanded "><a href="bpftrace/memory.html"><strong aria-hidden="true">2.2.</strong> Memory</a></li><li class="chapter-item expanded "><a href="bpftrace/fs.html"><strong aria-hidden="true">2.3.</strong> File Systems</a></li><li class="chapter-item expanded "><a href="bpftrace/disk.html"><strong aria-hidden="true">2.4.</strong> Disks</a></li><li class="chapter-item expanded "><a href="bpftrace/networking.html"><strong aria-hidden="true">2.5.</strong> Networking</a></li></ol></li><li class="chapter-item expanded "><a href="observability_tools/introdution.html"><strong aria-hidden="true">3.</strong> observability_tools</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="observability_tools/memory.html"><strong aria-hidden="true">3.1.</strong> Memory</a></li></ol></li><li class="chapter-item expanded "><a href="chapter_1/introdution.html"><strong aria-hidden="true">4.</strong> Technology Background</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="chapter_1/bpf.html"><strong aria-hidden="true">4.1.</strong> BPF</a></li></ol></li><li class="chapter-item expanded "><a href="file_systems/8_0.html"><strong aria-hidden="true">5.</strong> File Systems</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="file_systems/8_1.html"><strong aria-hidden="true">5.1.</strong> Terminology</a></li><li class="chapter-item expanded "><a href="file_systems/8_2.html"><strong aria-hidden="true">5.2.</strong> Models</a></li><li class="chapter-item expanded "><a href="file_systems/8_3.html"><strong aria-hidden="true">5.3.</strong> Concepts</a></li><li class="chapter-item expanded "><a href="file_systems/8_4.html"><strong aria-hidden="true">5.4.</strong> Architecture</a></li><li class="chapter-item expanded "><a href="file_systems/8_5.html"><strong aria-hidden="true">5.5.</strong> Methodology</a></li><li class="chapter-item expanded "><a href="file_systems/8_6.html"><strong aria-hidden="true">5.6.</strong> Observability Tools</a></li><li class="chapter-item expanded "><a href="file_systems/8_7.html"><strong aria-hidden="true">5.7.</strong> Experimentation</a></li><li class="chapter-item expanded "><a href="file_systems/8_8.html"><strong aria-hidden="true">5.8.</strong> Tuning</a></li><li class="chapter-item expanded "><a href="file_systems/8_9.html"><strong aria-hidden="true">5.9.</strong> Exercises</a></li></ol></li><li class="chapter-item expanded "><a href="network/network.html"><strong aria-hidden="true">6.</strong> Network</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="network/term.html"><strong aria-hidden="true">6.1.</strong> Terminology</a></li><li class="chapter-item expanded "><a href="network/models.html"><strong aria-hidden="true">6.2.</strong> Models</a></li><li class="chapter-item expanded "><a href="network/concepts.html"><strong aria-hidden="true">6.3.</strong> Concepts</a></li><li class="chapter-item expanded "><a href="network/architecture.html"><strong aria-hidden="true">6.4.</strong> Architecture</a></li><li class="chapter-item expanded "><a href="network/methodology.html"><strong aria-hidden="true">6.5.</strong> Methodology</a></li><li class="chapter-item expanded "><a href="network/observability.html"><strong aria-hidden="true">6.6.</strong> Observability Tools</a></li><li class="chapter-item expanded "><a href="network/experimentation.html"><strong aria-hidden="true">6.7.</strong> Experimentation</a></li><li class="chapter-item expanded "><a href="network/tuning.html"><strong aria-hidden="true">6.8.</strong> Tuning</a></li><li class="chapter-item expanded "><a href="network/exercises.html"><strong aria-hidden="true">6.9.</strong> Exercises</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">system-performance</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h2 id="linux-60-second-analysis"><a class="header" href="#linux-60-second-analysis">Linux 60-Second Analysis</a></h2>
<ol>
<li>
<p>uptime</p>
<p>this is a quick way to view the load average, which indicate the number of tasks(process) wanting to run. On Linux system, these numberts include process wanting to run on the CPUs, <strong>as well as processes blocked in uninterruptible  I/O</strong> (usually disk I/O).</p>
</li>
<li>
<p>dmesg | tail</p>
</li>
<li>
<p>vmstat 1</p>
<pre><code class="language-bash">--procs-- -----------------------memory---------------------- ---swap-- -----io---- -system-- --------cpu--------
   r    b         swpd         free         buff        cache   si   so    bi    bo   in   cs  us  sy  id  wa  st
   2    0            0      4390360        93524      1843900    0    0   171    25  103  252   2   1  97   0   0
   0    0            0      4384880        93524      1843900    0    0     0     0  544  975   1   0  99   0   0
   0    0            0      4386152        93524      1843964    0    0     0    16  932 2595   1   0  99   0   0

</code></pre>
<p><strong>r:</strong> the number of processes running on CPU and waiting for a turn. this provide a better signal than load averages for determining CPU saturation, as it does not include I/O. <strong>To interpret: an &quot;r&quot; value greater than CPU count indicates saturation</strong></p>
<p><strong>si and so:</strong> Swap-ins and swap-outs. if these are non-zero, you're out of memory.</p>
<p><strong>us, sy, id, wa, and st:</strong> These are breakdowns of CPU time, on average, across all CPUs. they are user time, system time(kernel), idle, wait I/O, and stolen time(the guest's own isolated driver domain).</p>
</li>
<li>
<p>mpstat -P ALL 1</p>
<p>This command prints per-CPU time broken down into states.</p>
<p><strong>high %iowait time</strong>, which can be explored with disk I/O tools, and <strong>high %sys time</strong>, which an be explored with syscall and kernel tracing, as well as CPU profiling.</p>
</li>
<li>
<p>pidstat 1</p>
<p>shows CPU usage per process.</p>
</li>
<li>
<p>iostat -xz 1</p>
<p>This tool shows storage device I/O metrics. The output columns for each disk device have line-wrapped here.</p>
<p><strong>await</strong>: The average time for the I/O in milliseconds. This is time that the application suffers, as it include both time queued and time being serviced. Larger-than-expected average times can be an indicator of device saturation or device problem.</p>
</li>
<li>
<p>free -m</p>
</li>
<li>
<p>sar -n DEV 1 </p>
<p>The sar tool has many modes for different groups of metrics. Here I'm using it to look at network device metrics. Check interface throughput rxKB/s and txKB/s to see if any limit may have been reached.</p>
</li>
<li>
<p>sar -n TCP,ETCP 1</p>
<p>TCP metrics and TCP error.</p>
<p><strong>active/s:</strong> 			Number of locally initiated TCP connections per second(e.g., via connect())</p>
<p><strong>passive/s:</strong> 		 Number of remotely initiated TCP connections per second (e.g, via accept())	</p>
<p><strong>retrans/s:</strong> 		  Number of TCP retransmits per second.</p>
</li>
<li>
<p>top</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bpftrace-one-line-commands"><a class="header" href="#bpftrace-one-line-commands">Bpftrace one-line commands</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h2 id="cpus"><a class="header" href="#cpus">CPUs</a></h2>
<ul>
<li>Trace new processes with arguments:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'tracepoint:syscalls:sys_enter_execve { join(args-&gt;argv); }'
</code></pre>
<ul>
<li>Count syscalls by process:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'tracepoint:raw_syscalls:sys_enter { @[pid, comm] = count(); }'
</code></pre>
<ul>
<li>Count syscalls by syscall probe name:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'tracepoint:syscalls:sys_enter_* { @[probe] = count(); }'
</code></pre>
<ul>
<li>Sample running process names at 99 Hertz:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'profile:hz:99 { @[comm] = count(); }'
</code></pre>
<ul>
<li>Sample user and kernel stacks at 49 Hertz, system wide, with the process name:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'profile:hz:49 { @[kstack, ustack, comm] = count(); }'
</code></pre>
<ul>
<li>Sample user-level stacks at 49 Hertz, for PID 189:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'profile:hz:49 /pid == 189/ { @[ustack] = count(); }'
</code></pre>
<ul>
<li>Sample user-level stacks 5 frames deep at 49 Hertz, for PID 189:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'profile:hz:49 /pid == 189/ { @[ustack(5)] = count(); }'804
</code></pre>
<ul>
<li>Sample user-level stacks at 49 Hertz, for processes named “mysqld”:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'profile:hz:49 /comm == &quot;mysqld&quot;/ { @[ustack] = count(); }'
</code></pre>
<ul>
<li>Count kernel CPU scheduler tracepoints:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'tracepont:sched:* { @[probe] = count(); }'
</code></pre>
<ul>
<li>Count off-CPU kernel stacks for context switch events:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'tracepont:sched:sched_switch { @[kstack] = count(); }'
</code></pre>
<ul>
<li>Count kernel function calls beginning with “vfs_”:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'kprobe:vfs_* { @[func] = count(); }'
</code></pre>
<ul>
<li>Trace new threads via pthread_create():</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'u:/lib/x86_64-linux-gnu/libpthread-2.27.so:pthread_create {printf(&quot;%s by %s (%d)\n&quot;, probe, comm, pid); }'
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="memory"><a class="header" href="#memory">Memory</a></h2>
<ul>
<li>Sum libc malloc() request bytes by user stack and process (high overhead):</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'u:/lib/x86_64-linux-gnu/libc.so.6:malloc {@[ustack, comm] = sum(arg0); }'
</code></pre>
<ul>
<li>Sum libc malloc() request bytes by user stack for PID 181 (high overhead):</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'u:/lib/x86_64-linux-gnu/libc.so.6:malloc /pid == 181/ {@[ustack] = sum(arg0); }'
</code></pre>
<ul>
<li>Show libc malloc() request bytes by user stack for PID 181 as a power-of-2 histogram (high overhead):</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'u:/lib/x86_64-linux-gnu/libc.so.6:malloc /pid == 181/ {@[ustack] = hist(arg0); }'
</code></pre>
<ul>
<li>Sum kernel kmem cache allocation bytes by kernel stack trace:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 't:kmem:kmem_cache_alloc { @bytes[kstack] = sum(args-&gt;bytes_alloc); }'
</code></pre>
<ul>
<li>Count process heap expansion (brk(2)) by code path:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'tracepoint:syscalls:sys_enter_brk { @[ustack, comm] = count(); }'
</code></pre>
<ul>
<li>Count page faults by process:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'software:page-fault:1 { @[comm, pid] = count(); }'bpftrace One-Liners
</code></pre>
<ul>
<li>Count user page faults by user-level stack trace:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 't:exceptions:page_fault_user { @[ustack, comm] = count(); }'
</code></pre>
<ul>
<li>Count vmscan operations by tracepoint:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'tracepoint:vmscan:* { @[probe]++; }'
</code></pre>
<ul>
<li>Count swapins by process:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'kprobe:swap_readpage { @[comm, pid] = count(); }'
</code></pre>
<ul>
<li>Count page migrations:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'tracepoint:migrate:mm_migrate_pages { @ = count(); }'
</code></pre>
<ul>
<li>Trace compaction events:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 't:compaction:mm_compaction_begin { time(); }'
</code></pre>
<ul>
<li>List USDT probes in libc:</li>
</ul>
<pre><code class="language-bash">bpftrace -l 'usdt:/lib/x86_64-linux-gnu/libc.so.6:*'
</code></pre>
<ul>
<li>List kernel kmem tracepoints:</li>
</ul>
<pre><code class="language-bash">bpftrace -l 't:kmem:*'
</code></pre>
<ul>
<li>List all memory subsystem (mm) tracepoints:</li>
</ul>
<pre><code class="language-bash">bpftrace -l 't:*:mm_*'
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="file-systems"><a class="header" href="#file-systems">File Systems</a></h2>
<ul>
<li>Trace files opened via openat(2) with process name:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 't:syscalls:sys_enter_openat { printf(&quot;%s %s\n&quot;, comm,str(args-&gt;filename)); }'
</code></pre>
<ul>
<li>Count read syscalls by syscall type:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'tracepoint:syscalls:sys_enter_*read* { @[probe] = count(); }'
</code></pre>
<ul>
<li>Count write syscalls by syscall type:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'tracepoint:syscalls:sys_enter_*write* { @[probe] = count(); }'
</code></pre>
<ul>
<li>Show the distribution of read() syscall request sizes:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'tracepoint:syscalls:sys_enter_read { @ = hist(args-&gt;count); }'
</code></pre>
<ul>
<li>Show the distribution of read() syscall read bytes (and errors):</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'tracepoint:syscalls:sys_exit_read { @ = hist(args-&gt;ret); }'
</code></pre>
<ul>
<li>Count read() syscall errors by error code:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 't:syscalls:sys_exit_read /args-&gt;ret &lt; 0/ { @[- args-&gt;ret] = count(); }'
</code></pre>
<ul>
<li>Count VFS calls:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'kprobe:vfs_* { @[probe] = count(); }'
</code></pre>
<ul>
<li>Count VFS calls for PID 181:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'kprobe:vfs_* /pid == 181/ { @[probe] = count(); }'
</code></pre>
<ul>
<li>Count ext4 tracepoints:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'tracepoint:ext4:* { @[probe] = count(); }'
</code></pre>
<ul>
<li>Count xfs tracepoints:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'tracepoint:xfs:* { @[probe] = count(); }'
</code></pre>
<ul>
<li>Count ext4 file reads by process name and user-level stack:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'kprobe:ext4_file_read_iter { @[ustack, comm] = count(); }'
</code></pre>
<ul>
<li>Trace ZFS spa_sync() times:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'kprobe:spa_sync { time(&quot;%H:%M:%S ZFS spa_sync()\n&quot;); }'
</code></pre>
<ul>
<li>Count dcache references by process name and PID:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'kprobe:lookup_fast { @[comm, pid] = count(); }'
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="disks"><a class="header" href="#disks">Disks</a></h2>
<ul>
<li>Count block I/O tracepoints events:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'tracepoint:block:* { @[probe] = count(); }'
</code></pre>
<ul>
<li>Summarize block I/O size as a histogram:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 't:block:block_rq_issue { @bytes = hist(args-&gt;bytes); }'
</code></pre>
<ul>
<li>Count block I/O request user stack traces:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 't:block:block_rq_issue { @[ustack] = count(); }'
</code></pre>
<ul>
<li>Count block I/O type flags:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 't:block:block_rq_issue { @[args-&gt;rwbs] = count(); }'bpftrace One-Liners
</code></pre>
<ul>
<li>Trace block I/O errors with device and I/O type:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 't:block:block_rq_complete /args-&gt;error/ {printf(&quot;dev %d type %s error %d\n&quot;, args-&gt;dev, args-&gt;rwbs, args-&gt;error); }'
</code></pre>
<ul>
<li>Count SCSI opcodes:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 't:scsi:scsi_dispatch_cmd_start { @opcode[args-&gt;opcode] = count(); }'
</code></pre>
<ul>
<li>Count SCSI result codes:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 't:scsi:scsi_dispatch_cmd_done { @result[args-&gt;result] = count(); }'
</code></pre>
<ul>
<li>Count SCSI driver function calls:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'kprobe:scsi* { @[func] = count(); }'
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="networking"><a class="header" href="#networking">Networking</a></h2>
<ul>
<li>Count socket accept(2)s by PID and process name:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 't:syscalls:sys_enter_accept* { @[pid, comm] = count(); }'
</code></pre>
<ul>
<li>Count socket connect(2)s by PID and process name:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 't:syscalls:sys_enter_connect { @[pid, comm] = count(); }'
</code></pre>
<ul>
<li>Count socket connect(2)s by user stack trace:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 't:syscalls:sys_enter_connect { @[ustack, comm] = count(); }'
</code></pre>
<ul>
<li>Count socket send/receives by direction, on-CPU PID, and process name:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'k:sock_sendmsg,k:sock_recvmsg { @[func, pid, comm] = count(); }'
</code></pre>
<ul>
<li>Count socket send/receive bytes by on-CPU PID and process name:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'kr:sock_sendmsg,kr:sock_recvmsg /(int32)retval &gt; 0/ { @[pid, comm] = sum((int32)retval); }'
</code></pre>
<ul>
<li>Count TCP connects by on-CPU PID and process name:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'k:tcp_v*_connect { @[pid, comm] = count(); }'
</code></pre>
<ul>
<li>Count TCP accepts by on-CPU PID and process name:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'k:inet_csk_accept { @[pid, comm] = count(); }'
</code></pre>
<ul>
<li>Count TCP send/receives by on-CPU PID and process name:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'k:tcp_sendmsg,k:tcp_recvmsg { @[func, pid, comm] = count(); }'
</code></pre>
<ul>
<li>TCP send bytes as a histogram:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'k:tcp_sendmsg { @send_bytes = hist(arg2); }'
</code></pre>
<ul>
<li>TCP receive bytes as a histogram:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'kr:tcp_recvmsg /retval &gt;= 0/ { @recv_bytes = hist(retval); }'
</code></pre>
<ul>
<li>Count TCP retransmits by type and remote host (assumes IPv4):</li>
</ul>
<pre><code class="language-bash">bpftrace -e 't:tcp:tcp_retransmit_* { @[probe, ntop(2, args-&gt;saddr)] = count(); }'
</code></pre>
<ul>
<li>Count all TCP functions (adds high overhead to TCP):</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'k:tcp_* { @[func] = count(); }'
</code></pre>
<ul>
<li>Count UDP send/receives by on-CPU PID and process name:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'k:udp*_sendmsg,k:udp*_recvmsg { @[func, pid, comm] = count(); }'
</code></pre>
<ul>
<li>UDP send bytes as a histogram:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'k:udp_sendmsg { @send_bytes = hist(arg2); }'
</code></pre>
<ul>
<li>UDP receive bytes as a histogram:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'kr:udp_recvmsg /retval &gt;= 0/ { @recv_bytes = hist(retval); }'
</code></pre>
<ul>
<li>Count transmit kernel stack traces:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 't:net:net_dev_xmit { @[kstack] = count(); }'
</code></pre>
<ul>
<li>Show receive CPU histogram for each device:</li>
</ul>
<pre><code class="language-bash">bpftrace -e 't:net:netif_receive_skb { @[str(args-&gt;name)] = lhist(cpu, 0, 128, 1); }'
</code></pre>
<ul>
<li>Count ieee80211 layer functions (adds high overhead to packets):</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'k:ieee80211_* { @[func] = count()'
</code></pre>
<ul>
<li>Count all ixgbevf device driver functions (adds high overhead to ixgbevf):</li>
</ul>
<pre><code class="language-bash">bpftrace -e 'k:ixgbevf_* { @[func] = count(); }'
</code></pre>
<ul>
<li>Count all iwl device driver tracepoints (adds high overhead to iwl):</li>
</ul>
<pre><code class="language-bash">bpftrace -e 't:iwlwifi:*,t:iwlwifi_io:* { @[probe] = count(); }'
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h2 id="memory-observability-tools"><a class="header" href="#memory-observability-tools">Memory observability tools</a></h2>
<ol>
<li>
<h3 id="vmstat"><a class="header" href="#vmstat">vmstat</a></h3>
<pre><code class="language-bash">vmstat -Sm 1 # to megabytes
vmstat -a 1  # print a breakdown of inactive and active from page cache
vmstat -w 1  # wide output
</code></pre>
</li>
<li>
<h3 id="psi-linux-pressure-stall-information-added-in-linux-420"><a class="header" href="#psi-linux-pressure-stall-information-added-in-linux-420">PSI (linux pressure stall information) added in linux 4.20</a></h3>
<pre><code class="language-bash">cat /proc/pressure/memory
#some avg10=2.84 avg60=1.23 avg300=0.32 total=1468344
#full avg10=1.85 avg60=0.66 avg300=0.16 total=702578
</code></pre>
<p>PSI statistics are also tracked per cgroup2</p>
</li>
<li>
<h3 id="swapon"><a class="header" href="#swapon">swapon</a></h3>
<pre><code class="language-bash">swapon
#NAME           TYPE       SIZE USED PRIO
#/dev/nvme0n1p7 partition 15.6G   0B   -2
</code></pre>
</li>
<li>
<h3 id="sar-system-activity-reporter"><a class="header" href="#sar-system-activity-reporter">sar (system activity reporter)</a></h3>
<ul>
<li>
<p><strong>-B:</strong> paging statistics</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: center">Statistics</th><th style="text-align: center">Description</th><th style="text-align: center">Unit</th></tr></thead><tbody>
<tr><td style="text-align: center">pgpgin/s</td><td style="text-align: center">Page-ins</td><td style="text-align: center">Kbytes/s</td></tr>
<tr><td style="text-align: center">pgpgout/s</td><td style="text-align: center">Page-outs</td><td style="text-align: center">Kbytes/s</td></tr>
<tr><td style="text-align: center">faults/s</td><td style="text-align: center">Both major and minor faults</td><td style="text-align: center">Count/s</td></tr>
<tr><td style="text-align: center">majflt/s</td><td style="text-align: center">Major faults</td><td style="text-align: center">Count/s</td></tr>
<tr><td style="text-align: center">pgfree/s</td><td style="text-align: center">Pages added to free list</td><td style="text-align: center">Count/s</td></tr>
<tr><td style="text-align: center">pgscank/s</td><td style="text-align: center">Pages scanned by background page-out daemon(kswapd)</td><td style="text-align: center">Count/s</td></tr>
<tr><td style="text-align: center"><strong>pgscand/s</strong></td><td style="text-align: center">Direct page scans</td><td style="text-align: center">Count/s</td></tr>
<tr><td style="text-align: center">pgsteal/s</td><td style="text-align: center">Page and swap cache reclaims</td><td style="text-align: center">Count/s</td></tr>
<tr><td style="text-align: center"><strong>%vmeff</strong></td><td style="text-align: center">Ratio of page steal/page scan,which shows page reclaim efficiency<br />The %vmeff metric is a useful measure of page reclaims efficiency. High means pages are successfully stolen from the inactive list(healthy); low means the system is struggling. the man page describes near 100% as high, and less than 30% as low.</td><td style="text-align: center">Percent</td></tr>
</tbody></table>
</div></li>
<li>
<p><strong>-H:</strong> Huge pages statistics</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: center">Statistics</th><th style="text-align: center">Description</th><th style="text-align: center">Unit</th></tr></thead><tbody>
<tr><td style="text-align: center">hbhugefree</td><td style="text-align: center">Free huge pages memory (large page size)</td><td style="text-align: center">Kbytes</td></tr>
<tr><td style="text-align: center">hbhugeused</td><td style="text-align: center">Used huge pages memory</td><td style="text-align: center">Kbytes</td></tr>
<tr><td style="text-align: center">%hugeused</td><td style="text-align: center">Huge page usage</td><td style="text-align: center">Percent</td></tr>
</tbody></table>
</div></li>
<li>
<p><strong>-r:</strong> Memory utilization</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: center">Statistics</th><th style="text-align: center">Description</th><th style="text-align: center">Unit</th></tr></thead><tbody>
<tr><td style="text-align: center">kbmemfree</td><td style="text-align: center">Free memory (completely unused)</td><td style="text-align: center">Kbytes</td></tr>
<tr><td style="text-align: center">kbavail</td><td style="text-align: center">Available memory,including pages that can be readily freed from the page cache</td><td style="text-align: center">Kbytes</td></tr>
<tr><td style="text-align: center">kbmemused</td><td style="text-align: center">Used memory (excluding the kernel)</td><td style="text-align: center">Kbytes</td></tr>
<tr><td style="text-align: center">%memused</td><td style="text-align: center">Memory usage</td><td style="text-align: center">Percent</td></tr>
<tr><td style="text-align: center">kbbuffers</td><td style="text-align: center">Buffer cache size</td><td style="text-align: center">Kbytes</td></tr>
<tr><td style="text-align: center">kbcached</td><td style="text-align: center">Page cache size</td><td style="text-align: center">Kbytes</td></tr>
<tr><td style="text-align: center">kbcommit</td><td style="text-align: center">Main memory committed: an estimate of the amount needed to serve the current workload</td><td style="text-align: center">Kbytes</td></tr>
<tr><td style="text-align: center">%commit</td><td style="text-align: center">Main memory committed for current workload, estimate</td><td style="text-align: center">Percent</td></tr>
<tr><td style="text-align: center">kbactive</td><td style="text-align: center">Active list memory size</td><td style="text-align: center">Kbytes</td></tr>
<tr><td style="text-align: center">kbinact</td><td style="text-align: center">Inactive list memory size</td><td style="text-align: center">Kbytes</td></tr>
<tr><td style="text-align: center">kbdirtyw</td><td style="text-align: center">Modified memory to be written to disk</td><td style="text-align: center">Kbytes</td></tr>
</tbody></table>
</div></li>
<li>
<p><strong>-r ALL</strong></p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: center">Statistics</th><th style="text-align: center">Description</th><th style="text-align: center">Unit</th></tr></thead><tbody>
<tr><td style="text-align: center">kbanonpg</td><td style="text-align: center">Process anonymous memory</td><td style="text-align: center">Kbytes</td></tr>
<tr><td style="text-align: center">kbslab</td><td style="text-align: center">Kernel slab cache size</td><td style="text-align: center">Kbytes</td></tr>
<tr><td style="text-align: center">kbkstack</td><td style="text-align: center">Kernel stack space size</td><td style="text-align: center">Kbytes</td></tr>
<tr><td style="text-align: center">kbpgtbl</td><td style="text-align: center">Lowest-level page table size</td><td style="text-align: center">Kbytes</td></tr>
<tr><td style="text-align: center">kbvmuused</td><td style="text-align: center">Used virtual address space</td><td style="text-align: center">Kbytes</td></tr>
</tbody></table>
</div></li>
<li>
<p><strong>-S:</strong> Swap space statistics</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: center">Statistics</th><th style="text-align: center">Description</th><th style="text-align: center">Unit</th></tr></thead><tbody>
<tr><td style="text-align: center">kbswapfree</td><td style="text-align: center">Free swap space</td><td style="text-align: center">Kbytes</td></tr>
<tr><td style="text-align: center">kbswapused</td><td style="text-align: center">Used swap space</td><td style="text-align: center">Kbytes</td></tr>
<tr><td style="text-align: center">%swpused</td><td style="text-align: center">Used swap space</td><td style="text-align: center">Percent</td></tr>
<tr><td style="text-align: center">kbswpcad</td><td style="text-align: center">Cached swap space: this resides in both main memory and the swap device and so can be paged out without disk  I/O</td><td style="text-align: center">Kbytes</td></tr>
<tr><td style="text-align: center">%swpcad</td><td style="text-align: center">Ratio of cached swap versus used swap</td><td style="text-align: center">Percent</td></tr>
</tbody></table>
</div></li>
<li>
<p><strong>-W:</strong> Swapping statistics</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: center">Statistics</th><th style="text-align: center">Description</th><th style="text-align: center">Unit</th></tr></thead><tbody>
<tr><td style="text-align: center">pswpin/s</td><td style="text-align: center">Page-ins(Linux &quot;swap-ins&quot;)</td><td style="text-align: center">Pages/s</td></tr>
<tr><td style="text-align: center">pswpout/s</td><td style="text-align: center">Page-outs(Linux &quot;swap-outs&quot;)</td><td style="text-align: center">Pages/s</td></tr>
</tbody></table>
</div></li>
</ul>
</li>
<li>
<h3 id="slabtop-prints-kernel-slab-cache-usage-from-the-slab-allocator"><a class="header" href="#slabtop-prints-kernel-slab-cache-usage-from-the-slab-allocator">slabtop: prints kernel slab cache usage from the slab allocator</a></h3>
<pre><code class="language-bash">slabtop -sc # sort by cache size
</code></pre>
</li>
<li>
<h3 id="numastat"><a class="header" href="#numastat">numastat</a></h3>
</li>
<li>
<h3 id="ps"><a class="header" href="#ps">ps</a></h3>
<pre><code class="language-bash">ps -oe pid,pmem,vsz,rss,comm # using the SVR4-style -o option
</code></pre>
</li>
<li>
<h3 id="top"><a class="header" href="#top">top</a></h3>
<pre><code class="language-bash">top -o %MEM # sort by memory usage
</code></pre>
</li>
<li>
<h3 id="pmap"><a class="header" href="#pmap">pmap</a></h3>
<pre><code class="language-bash">pmap -x  5187
pmap -X  5187  # more details
pmap -XX 5187
</code></pre>
</li>
<li>
<h3 id="perf"><a class="header" href="#perf">perf</a></h3>
<ul>
<li>
<p>One-Liners</p>
<pre><code class="language-bash"># Sample page faults (RSS growth) with stack traces system wide
perf record -e page-faults -a -g
# Record all page faults with stack traces for PID 1843, for 60 seconds
perf record -e page-faults -c 1 -p 1822 -g -- sleep 60
# Record heap growth via brk(2)
perf record -e syscalls:sys_enter_brk -a -g
# Record page migrations on NUMA systems
perf record -e migrate:mm_migrate_pages -a
# Count all kmem events, printing a report every second
perf stat -e 'kmem:*' -a -I 1000
# Count all vmscan events, printing a report every second
perf stat -e 'vmscan:*' -a -I 1000
# Count memory compaction events, printing a report every second
perf stat -e 'compaction:*' -a -I 1000
# Trace kswapd wakeup events with stack traces
perf record -e vmscan:mm_vmscan_wakeup_kswapd  -ag
# Profile memory access for the given command
perf mem record command
# Summarize a memory profile
perf mem report
# Print all events
perf script --header
</code></pre>
<p>How to generate flame graph?</p>
<pre><code class="language-bash"># perf record -e page-faults -a -g -- sleep 60
# perf script --header &gt; out.stacks
$ git clone https://github.com/brendangregg/FlameGraph; cd FlameGraph
$ ./stackcollapse-perf.pl &lt; ../out.stacks | ./flamegraph.pl --hash \
--bgcolor=green --count=pages --title=&quot;Page Fault Flame Graph&quot; &gt; out.svg
</code></pre>
</li>
</ul>
</li>
<li>
<h3 id="drsnoop"><a class="header" href="#drsnoop">drsnoop</a></h3>
<p>is a BCC tool for tracing the direct reclaim approach to freeing memory, showing the process affected and the latency: the time taken for the reclaim.</p>
<p>It can be used to quantify the application performance impact of a memory-constrained system.</p>
<pre><code class="language-bash">drsnoop -T
</code></pre>
</li>
<li>
<h3 id="wssworking-set-size"><a class="header" href="#wssworking-set-size">wss(working set size)</a></h3>
<p>this tools works by resetting the PTE accessed bit for every page in a process, pausing for an interval, and then checking the bits to see which have been set.</p>
<p>WARNINGS: this tool uses <code>/proc/PID/clear_refs</code> and <code>/proc/PID/smaps</code>, which can cause slightly higher application latency (e.g, <strong>10%</strong>) while the kernel walks page structures. For large processes (&gt; 100Gbytes), this duration of higher latency can last over one second, during which this tool is consuming system CPU time.</p>
<p>Keep these overheads in mind. this tool also resets the referenced flag, which might confuse the kernel as to which pages to reclaim, especially if swapping is active.</p>
</li>
<li>
<h3 id="bpftrace"><a class="header" href="#bpftrace">bpftrace</a></h3>
<pre><code class="language-bash"># Show libc malloc() request bytes by user stack for PID 181 as a power-of-2 histogram (high overhead)
bpftrace -e 'uprobe:/lib/x86_64-linux-gnu/libc.so.6:malloc /pid == 181/ { @[ustack] = hist(arg0); }'

# Sum kernel kmem cache allocation bytes by kernel stack trace
bpftrace -e 't:kmem:kmem_cache_alloc {@bytes[kstack] = sum(args-&gt;bytes_alloc);}'

# Count process heap expansion (brk(2)) by code path
bpftrace -e 'tracepoin:syscalls:sys_enter_brk {@[ustack,comm] = count()}'

# Count page faults by process
# Tracing page faults shows when a process grows in memory size.
bpftrace -e 'software:page-fault:1 { @[comm, pid] = count(); }'

# Count user page faults by user-level stack trace
bpftrace -e 't:exceptions:page_fault_user {@[ustack, comm] = count(); }' &gt; out.stacks
git clone https://github.com/brendangregg/FlameGraph; cd FlameGraph ./stackcollapse-bpftrace.pl &lt; ../out.stacks | ./flamegraph.pl --hash \
--bgcolor=green --count=pages --title=&quot;Page Fault Flame Graph&quot; &gt; out.svg

# Count vmscan operations by tracepoint
bpftrace -e 'tracepoint:vmscan:* {@[probe] = count(); }'

# Count swapins by process
bpftrace -e 'kprobe:swap_readpage {@[comm,pid] = count()}'

# Count page migration
bpftrace -e 'tracepoint:migration:mm_migrate_pages {@ = count(); }'

# Trace compaction events
bpftrace -e 't:compaction:mm_compaction_begin { time(); }'

# List USDT probes in libc
bpftrace -e 'usdt:/lib/x86_64-linux-gnu/libc.so.6:*'

# List kernel kmem tracepoints:
bpftrace -l 't:kmem:*'

# List all memory subsystem (mm) tracepoints
bpftracce -l 't:*:mm_*'
bpftrace -l 'tracepoint:kmem:*'

# Listing USDT probes for libc on ubuntu, if the tracepoints and USDT probes are insufficient, consider using dynamic instrumentation with kprobes and uprobes.
bpftrace -l 'usdt:/lib/x86_64-linux-gnu/libc.so.6'
</code></pre>
<p>Since memory events can be very frequent, instrumenting then can consume significant overhead. malloc(3) functions form user space can be called millions of times per second, and with the current uprobes overhead.</p>
<p>tracing them can slow a target two-fold or more, use caution and find ways to reduce this overhead, such as using maps to summarize statistics instead of printing per-event details, and tracing the fewest possible events.</p>
</li>
<li>
<p><strong>pmcarch:</strong> CPU cycle usage including LLC misses</p>
</li>
<li>
<p><strong>tlbstat:</strong> Summarize TLB cycles</p>
</li>
<li>
<p><strong>free:</strong> Cache capacity statistics</p>
</li>
<li>
<p><strong>cachestat:</strong> Page cache statistics</p>
</li>
<li>
<p><strong>oomkill:</strong> shows extra info on OOM kill events</p>
</li>
<li>
<p><strong>memleak:</strong> Shows possible memory leak code paths</p>
</li>
<li>
<p><strong>mmapsnoop:</strong> Trace mmap(2) calls system-wide</p>
</li>
<li>
<p><strong>brkstack:</strong> Show brk() calls with user stack traces</p>
</li>
<li>
<p><strong>shmsnoop:</strong> Traces shared memory calls with details</p>
</li>
<li>
<p><strong>faults:</strong> Show page faults, by user stack trace</p>
</li>
<li>
<p><strong>ffaults:</strong> Show page faults, by filename</p>
</li>
<li>
<p><strong>vmscan:</strong> Measures VM  scanner shrink and reclaim times</p>
</li>
<li>
<p><strong>swapin:</strong> Shows swap-ins by process</p>
</li>
<li>
<p><strong>hfaults:</strong> Shows huge page faults, by process</p>
</li>
<li>
<p><strong>dmesg:</strong> Check for &quot;Out of memory&quot; message from OOM killer.</p>
</li>
<li>
<p><strong>dmidecode:</strong> Show BIOS information for memory bank.</p>
</li>
<li>
<p><strong>tiptop:</strong> A version of top(1) that displays PMC statistics by process.</p>
</li>
<li>
<p><strong>valgrind:</strong> A performance analysis suite.</p>
</li>
<li>
<p><strong>iostat:</strong> if the swap device is a physical disk or slice, device I/O may be observable using iostat(1).</p>
</li>
<li>
<p><code>/proc/zoneinfo</code>: Statistics for memory zone.</p>
</li>
<li>
<p><code>/proc/buddyinfo:</code> Statistics for the kernel buddy allocator for pages.</p>
</li>
<li>
<p><code>/proc/pagetypeinfo:</code> Kernel free memory page statistics; can be used to help debug issues of kernel memory fragmentation.</p>
</li>
<li>
<p><code>/proc/devices/system/node/node*/numastat</code>: statistics for NUMA nodes.</p>
</li>
<li>
<p><strong>SysRq m:</strong> Magic SysRq has an &quot;m&quot; key to dump memory info to the console.</p>
<pre><code class="language-bash">echo m &gt; /proc/sysrq-trigger
dmesg
</code></pre>
<p>This can be useful if the system has locked up, as it may still be possible to request this information using the SysRq key sequence on the console keyboard, if available.%</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><p>Technology Background</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="bpf"><a class="header" href="#bpf">BPF</a></h2>
<ol>
<li>
<p><strong>BPF</strong> was originally developed for the <strong>BSD</strong> operation system.</p>
</li>
<li>
<p><strong>BPF</strong> works in an interesting way: A filter expression is defined by the end user using an instruction set for a BPF virtual machine (sometimes called the BPF byte-code) and then passed to the kernel for execution by a interpreter.</p>
</li>
<li>
<p>(pros) this method allows filtering to occur in the kernel level without costly copies of each packet going to the user-level processes.(improving performance)</p>
</li>
<li>
<p>(pros) it also provide safety, as filters from user space can be verified as being safe before execution.</p>
</li>
<li>
<p>Extended BPF(<strong>eBPF</strong>) added more registers, switched from 32-bit to 64-bit words, created flexible BPF &quot;map&quot; storage, and allowed calls to some restricted kernel functions. it was also designed to be be JITed with a one-to-one mapping instructions and registers, allowing prior native instruction optimization techniques to be reused for BPF. the BPF verifier was also updated to handle these extensions and reject any unsafe code.</p>
</li>
<li>
<p><strong>BPF</strong> programs can execute custom latency calculations and statistical  summaries.</p>
</li>
<li>
<p>what makes <strong>BPF</strong> different is that it is also efficient and production environments withouts needing to add any new kernel components!.</p>
<pre><code class="language-bash">bitehist #shows the size of disk I/O as a histogram
</code></pre>
</li>
<li>
<p><strong>BPF</strong> can be programmed via one of the many front end available. The main ones for tracing are,from lowest-to-highest-level language.</p>
<ul>
<li>LLVM IR</li>
<li>BCC</li>
<li>bpftrace</li>
</ul>
</li>
<li>
<p>bpftool(8) was added in linux 4.15 for viewing and manipulation BPF objects,including programs and maps.</p>
</li>
<li>
<p>the <code>bpftool perf</code> subcommand shows BPF programs attached via <code>perf_event_open()</code>,witch is the norm for BCC and bpftrace programs on linux 4.17 and later.</p>
<pre><code class="language-bash">sudo apt-get install binutils-dev
sudo apt-get install libreadline-dev
cd &lt;linux-source-directory&gt;/tools/bpf/
make
bpftool prog dump xlated id 263 visual &gt; biolatency_done.dot #graphViz
dot -Tpng -Elen=2.5 biolatency_done.dot -o biolatency_done.png
</code></pre>
</li>
<li>
<p>The <code>prog dump jited</code> subcommand shows the machine code for the processor that is executed.</p>
</li>
<li>
<p>The <code>btf dump id &lt;id-number&gt;</code> shows the BTF IDs.</p>
</li>
<li>
<p>A <strong>BPF</strong> program cannot call arbitrary kernel functions. to accomplish certain tasks with this limitation, &quot;helper&quot; functions that BPF can call have been provided.</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">BPF Helper Function</th><th>Description</th></tr></thead><tbody>
<tr><td style="text-align: left">bpf_map_lookup_elem(map, key)</td><td><strong>Finds</strong> a key in a map and returns its value(pointer).</td></tr>
<tr><td style="text-align: left">bpf_map_update_elem(map,key,value,flags)</td><td><strong>Update</strong> the value of the entry selected by key.</td></tr>
<tr><td style="text-align: left">bpf_map_delete_elem(map, key)</td><td><strong>Deletes</strong> the entry selected by key from the map.</td></tr>
<tr><td style="text-align: left">bpf_probe_read(dst, size, src)</td><td>Safely reads size bytes from address src n and stores in dst.</td></tr>
<tr><td style="text-align: left">bpf_ktime_get_ns(</td><td>Returns the time since boot,in nanoseconds.</td></tr>
<tr><td style="text-align: left">bpf_trace_printk(fmt, fmt_size, ...)</td><td>A debugging helper that writes to TraceFs trace{_pipe}.</td></tr>
<tr><td style="text-align: left">bpf_get_current_pid_tgid()</td><td>Returns a u64 containing the current TGID (what user space calls the PID) in the upper bits and current PID (what user space calls the kernel thread ID) in the lower bits.</td></tr>
<tr><td style="text-align: left">bpf_perf_event_output(ctx, map, data, size)</td><td>Writes data to the perf_event ring buffers; this is used for per-event output.</td></tr>
<tr><td style="text-align: left">bpf_get_stackid(ctx, map, flags)</td><td>Fetches a user or kernel stack trace and returns an identifier.</td></tr>
<tr><td style="text-align: left">bpf_get_current_task()</td><td>Returns the current task struct. this contains many details about the running process and links to other structs containing system state. Note that these are all considered an unstable API.</td></tr>
<tr><td style="text-align: left">pbf_probe_read_str(dst, size, ptr)</td><td>Copies a NULL terminated string from an unsafe pointer to the destination, limited by size (including the NULL byte).</td></tr>
<tr><td style="text-align: left">bpf_perf_event_read_value(map, flags, buf, size)</td><td>Reads a perf_event counter and stores it in the buf. This is a way to read PMCs during a BPF program.</td></tr>
<tr><td style="text-align: left">bpf_get_current_cgroup_id()</td><td>Returns the current cgroup ID.</td></tr>
<tr><td style="text-align: left">bpf_spin_lock(lock)<br />bpf_spin_unlock(lock)</td><td>Concurrency control for network programs.</td></tr>
<tr><td style="text-align: left">bpf_current_comm(buf, buf_size)</td><td>Copies the task name to the buffer.</td></tr>
</tbody></table>
</div></li>
<li>
<p>The term current in these descriptions refers to the currently running thread. the thread that is currently on-CPU.</p>
</li>
<li>
<p><code>include/uapi/linux/bpf.h</code> file often provides detailed documentation for these helpers.</p>
</li>
<li>
<p><code>bpf_probe_read()</code> is a particularly important helper. Memory access in BPF is restricted to BPF registers and the stack. Arbitrary memory(such as other kernel memory outside of BPF) must be read via <code>pbf_probe_read()</code>, witch performs safety checks and disables page faults to ensure that the reads do not cause faults from probe context (witch could cause kernel problems).</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="file-systems-1"><a class="header" href="#file-systems-1">File Systems</a></h1>
<ol>
<li>File system performance often matters more to the application than disk or storage device performance, because it is the file system that applications interact with and wait for.</li>
<li>File systems can use caching, buffering, and asynchronous I/O</li>
<li>System performance analysis and monitoring tools have historically focused on the disk performance, leaving file system performance as a blind stop.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="terminology"><a class="header" href="#terminology">Terminology</a></h1>
<ol>
<li><strong>File system:</strong>  An organization of data as file and directories, with file-based interface for accessing them, and file permissions to control access.</li>
<li><strong>File system cache:</strong> An area of main memory used to cache file system contents.</li>
<li><strong>Operations:</strong> File system operations are requests of the file system, including read(2), write(2), open(2),close(2) and other operations.</li>
<li><strong>Logical I/O:</strong> I/O issued by the application to the file system.</li>
<li><strong>Physical I/O:</strong> I/O issued directly to disks by the file system (or via raw I/O)</li>
<li><strong>inode:</strong> An index node (inode) is a data structure containing metadata for a file system object, including permissions, timestamps, and data pointers.</li>
<li><strong>VFS:</strong> Virtual file system, a kernel interface to abstract and support different file system types.</li>
<li><strong>Volume</strong>: An instance of storage providing more flexibility than using a whole storage device. A volume may be a portion of a device, or multiple devices.</li>
<li><strong>Throughput</strong>: The current data transfer rate between applications and the file system, measured in bytes per second.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="models"><a class="header" href="#models">Models</a></h1>
<ol>
<li>One approach for studying file system performance is to treat it as a black box, focusing on the latency of the object operations.</li>
</ol>
<h2 id="file-system-cache"><a class="header" href="#file-system-cache">File System Cache</a></h2>
<ol>
<li>file system cache stored in main memory.</li>
<li>The read returns data either cache(cache hit) or from disk(cache miss).</li>
<li>Cache miss are stored in the cache, populating the cache(warming up).</li>
<li>The file system cache may also buffer writes to be written (flushed) later.</li>
<li>Kernels often provide a way to bypass the cache if desired.</li>
</ol>
<h2 id="second-level-cache"><a class="header" href="#second-level-cache">Second-Level Cache</a></h2>
<ol>
<li>Second-level cache may be any memory type. RAM -&gt; Flash Memory -&gt; High Density Disks</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="concepts"><a class="header" href="#concepts">Concepts</a></h1>
<ol>
<li>The following are a selection of important file system performance concepts.</li>
</ol>
<h2 id="file-system-latency"><a class="header" href="#file-system-latency">File System Latency</a></h2>
<ol>
<li>File system latency is the main indicator of file system performance, measuring the time from a logical file system request to its fulfillment.</li>
<li>It encompasses time spent within the file system and disk I/O subsystem, as well as waiting on disk devices (physical I/O).</li>
<li>Application threads often pause during a request to wait for file system actions to finish, meaning file system latency directly impacts application performance.</li>
<li>Exceptions where applications might not be directly affected include the use of non-blocking I/O, prefetching (Section 8.3.4), and when I/O is initiated from an asynchronous thread.</li>
<li>Historically, operating systems have not made file system latency easily visible, focusing more on disk device-level statistics.</li>
<li>But sometimes, these stats don't reflect how well apps are running.</li>
<li>For instance, file systems sometimes do background tasks like flushing data, causing spikes in disk activity.</li>
<li>This might look bad on disk stats, but it doesn't mean apps are waiting for it to finish.</li>
<li>Check Section 8.3.12 for more examples of this.</li>
</ol>
<h2 id="caching"><a class="header" href="#caching">Caching</a></h2>
<ol>
<li>The file system often uses main memory as a cache to speed up operations.</li>
<li>This means applications can access data faster because it's stored in memory rather than on slower disks.</li>
<li>As time goes on, the cache grows, reducing available memory for the operating system. But don't worry, this is normal.</li>
<li>The idea is: if there's spare memory, use it. When applications need more memory, the kernel should free some from the cache.</li>
<li>File systems use caching for reading and buffering for writing, which helps improve performance.</li>
<li>Different types of cache are used by both the file system and the block device subsystem.</li>
</ol>
<div class="table-wrapper"><table><thead><tr><th>Cache</th><th>Example</th></tr></thead><tbody>
<tr><td>Page cache</td><td>Operating system page cache</td></tr>
<tr><td>File system primary cache</td><td><code>ZFS ARC</code></td></tr>
<tr><td>File system secondary cache</td><td><code>ZFS L2ARC</code></td></tr>
<tr><td>Directory cache</td><td>dentry cache</td></tr>
<tr><td>inode cache</td><td>inode cache</td></tr>
<tr><td>Device cache</td><td><code>ZFS vdev</code></td></tr>
<tr><td>Block device cache</td><td>Buffer cache</td></tr>
</tbody></table>
</div>
<h2 id="random-vs-sequential-io"><a class="header" href="#random-vs-sequential-io">Random vs. Sequential I/O</a></h2>
<ol>
<li>File system operations can be random or sequential, depending on where they happen in the file.</li>
<li>Sequential operations follow each other, starting where the previous one ended.</li>
<li>Random operations have no pattern; they occur anywhere in the file.</li>
<li>A random workload might involve accessing many different files in no particular order.</li>
<li>Due to certain storage devices' performance characteristics (see Chapter 9, Disks), file systems aim to minimize random I/O by arranging file data sequentially and contiguously on disk.</li>
<li>Fragmentation occurs when file systems fail to organize data effectively, causing files to be scattered across the drive and turning sequential logical I/O into random physical I/O.</li>
<li>File systems track logical I/O access patterns to identify sequential workloads and enhance performance through techniques like prefetching or read-ahead.</li>
<li>These performance-improving techniques are more beneficial for rotational disks compared to flash drives.</li>
</ol>
<h2 id="prefetch"><a class="header" href="#prefetch">Prefetch</a></h2>
<ol>
<li>A common file system workload involves sequentially reading a large amount of file data, such as during a file system backup.</li>
<li>This data may not fit in the cache or may only be read once, resulting in a low cache hit ratio.</li>
<li><strong>Prefetch</strong> is a feature that addresses this issue by detecting sequential read patterns based on file I/O offsets.</li>
<li>It predicts and fetches data from disk before the application requests it, populating the cache.</li>
<li>If the application subsequently reads the prefetched data, it results in a cache hit, improving performance.</li>
<li>Example scenario:
<ol>
<li>Application requests file read.</li>
<li>Data not in cache, so file system reads from disk.</li>
<li>If offsets are sequential, file system issues additional prefetch reads.</li>
<li>Initial read completes, data passed to application.</li>
<li>Prefetch reads complete, caching data for future reads.</li>
<li>Subsequent application reads are faster from cached data in RAM.</li>
</ol>
</li>
<li>Effective prefetching greatly improves sequential read performance by keeping disks ahead of application requests.</li>
<li>Poor prefetching, however, leads to unnecessary I/O, polluting the cache and consuming resources.</li>
<li>File systems usually allow prefetch settings to be adjusted for optimal performance.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="architecture"><a class="header" href="#architecture">Architecture</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="methodology"><a class="header" href="#methodology">Methodology</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="observability-tools"><a class="header" href="#observability-tools">Observability Tools</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="experimentation"><a class="header" href="#experimentation">Experimentation</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tuning"><a class="header" href="#tuning">Tuning</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="exercises"><a class="header" href="#exercises">Exercises</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="network"><a class="header" href="#network">Network</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="terminology-1"><a class="header" href="#terminology-1">Terminology</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="models-1"><a class="header" href="#models-1">Models</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="concepts-1"><a class="header" href="#concepts-1">Concepts</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="architecture-1"><a class="header" href="#architecture-1">Architecture</a></h1>
<h2 id="software"><a class="header" href="#software">Software</a></h2>
<ol>
<li>Networking software includes the <strong>network stack</strong>, <strong>TCP</strong>, and <strong>device drivers</strong>.</li>
</ol>
<h3 id="network-stack"><a class="header" href="#network-stack">Network Stack</a></h3>
<ol>
<li>On modern kernels the stack is multithreaded, and inbound packets can be processed by multiple CPUs.</li>
</ol>
<h4 id="linux"><a class="header" href="#linux">Linux</a></h4>
<ol>
<li>
<p>On Linux systems, the network stack is a core kernel component.</p>
</li>
<li>
<p>device drivers are additional modules.</p>
</li>
<li>
<p>Packets are passed through these kernel components as the struct <code>sk_buff</code> (socket buffer) data type.</p>
</li>
<li>
<p>there may also be queueing in the IP layer (not pictured) for packet reassembly.</p>
</li>
<li>
<p><strong>Application</strong>: This is the highest level where user applications operate. Applications use network services to send and receive data over the network.</p>
<p><strong>Libraries</strong>: These provide a set of functions for the application to use for networking, abstracting the complexity of direct system calls.</p>
<p><strong>System Calls</strong>: These are the interfaces provided by the operating system kernel that applications call to perform network operations like send and receive data.</p>
<p><strong>Kernel</strong>: The central component of the OS that manages operations between hardware and software.</p>
<ul>
<li><strong>VFS (Virtual File System)</strong>: It provides an abstraction layer for file system operations and might also be involved in network operations when data is written to or read from network sockets as if they were files.</li>
<li><strong>Socket</strong>: A network socket is an endpoint for sending or receiving data across a computer network. Sockets have buffers for sending and receiving data.</li>
<li><strong>TCP/UDP/ICMP</strong>: These are different protocols for handling network communication.
<ul>
<li>TCP (Transmission Control Protocol) provides reliable, ordered, and error-checked delivery of a stream of data.</li>
<li>UDP (User Datagram Protocol) is a simpler, connectionless Internet protocol that allows sending datagrams without establishing a connection.</li>
<li>ICMP (Internet Control Message Protocol) is used for diagnostic purposes and error reporting, not typically for sending and receiving application data.</li>
</ul>
</li>
<li><strong>IP (Internet Protocol)</strong>: This protocol is designed for sending packets across the network using IP addresses to identify the source and destination.</li>
<li><strong>Queuing Discipline (qdisc)</strong>: This is a set of rules for how packets should be processed for transmission, including ordering, prioritizing, and scheduling packets.</li>
<li><strong>Driver Queue</strong>: Each network interface card (NIC) driver has its own queue to buffer packets before they are transmitted or after they are received.</li>
<li><strong>NIC / Virtual Device</strong>: The physical or virtual device that connects a computer to a network. The NIC has its own set of drivers that interact with the rest of the computer's hardware and software.</li>
<li><strong>Device Drivers</strong>: These are specific software that controls the hardware device, in this case, the network interface card.</li>
</ul>
</li>
<li>
<p>when you're writing a network driver, part of your job is to handle the frames that are received from the network. Here's how it generally works:</p>
<ol>
<li><strong>Receiving Frames</strong>: The network interface card (NIC) receives frames from the physical medium (like an Ethernet cable) and places them into its hardware buffer.</li>
<li><strong>Interrupt</strong>: Once the frame is received, the NIC typically generates an interrupt to signal the CPU that data has arrived.</li>
<li><strong>Driver's Role</strong>: The network driver, which you would be writing, responds to this interrupt. It reads the frame from the NIC's hardware buffer into system memory.</li>
<li><strong>Passing Up</strong>: After the frame is in system memory, the driver then hands it off to the operating system's networking stack, which processes it at various layers (like IP, TCP/UDP, etc.) until it reaches the application layer if it's incoming data.</li>
<li><strong>Sending Frames</strong>: For outgoing data, the process is reversed. The application sends data down the stack, which eventually hands it off to the network driver. The driver then places this data into the NIC's hardware buffer for transmission on the network.</li>
<li><strong>Buffer Management</strong>: Network drivers often implement or interact with a ring buffer or a similar data structure in system memory to efficiently manage the packets that are waiting to be processed.</li>
</ol>
<p>Writing a network driver involves managing these buffers, handling interrupts, and interfacing with the operating system's networking subsystems, as well as dealing with the specific hardware operations of the network device. It requires a good understanding of both the hardware and the software stack that the driver interacts with.</p>
</li>
<li>
<p><code>struct sk_buff</code>, commonly known as <code>sk_buff</code>, is a data structure in the Linux kernel networking stack that represents network packets. It holds the packet's content and its associated metadata, such as timestamps, network headers, and the origin and destination of the packet. <code>sk_buff</code> is used to manage and manipulate packets as they flow through the network stack, with functions provided by the kernel for common operations like resizing or modifying the data buffer. It's a fundamental structure that encapsulates both the packet's data and the control information used by the networking subsystem.</p>
</li>
</ol>
<h3 id="tcp-connection-queues"><a class="header" href="#tcp-connection-queues">TCP Connection Queues</a></h3>
<p><strong>1. Backlog Queues:</strong></p>
<ul>
<li><strong>Purpose:</strong> Manage bursts of inbound TCP connections.</li>
<li><strong>Types:</strong>
<ul>
<li><strong>SYN Backlog:</strong> For connections in the TCP handshake phase.</li>
<li><strong>Listen Backlog:</strong> For established connections awaiting application acceptance.</li>
</ul>
</li>
</ul>
<p><strong>2. Queue Management Evolution:</strong></p>
<ul>
<li><strong>Early Systems:</strong> Used a single queue, <strong>vulnerable to SYN flood attacks</strong>.</li>
<li><strong>SYN Flood Attack:</strong> Denial of Service (DoS) attack involving numerous bogus SYN requests to a TCP port, blocking legitimate connections.</li>
</ul>
<p><strong>3. Improved Management with Two Queues:</strong></p>
<ul>
<li><strong>Dual Queue System:</strong> Separates potentially connections from legitimate ones.</li>
<li><strong>Benefits:</strong>
<ul>
<li>
<p><strong>Staging for Unverified Connections:</strong> The SYN Backlog acts as a filter.</p>
</li>
<li>
<p><strong>Established Connections:</strong> Only verified connections reach the Listen Backlog.</p>
</li>
<li>
<p><strong>Optimized for Attack Mitigation:</strong> The SYN Backlog is lengthened and optimized to handle SYN floods with minimal metadata storage.</p>
</li>
<li>
<p><strong>SYN Cookies:</strong> SYN cookies are a method of handling SYN requests without having to allocate significant resources for each connection. Instead of storing each incoming SYN request in a queue, the server sends back a SYN-ACK response with a specially crafted sequence number (the &quot;cookie&quot;). This sequence number is generated based on the IP address, port number, and other characteristics of the incoming SYN request.</p>
<p><strong>Bypassing the First Queue:</strong>  the server does not need to store the state of each incoming SYN request in the SYN backlog. Instead, it relies on the client to respond correctly to the SYN-ACK with this special sequence number. If the client is legitimate and completes the handshake using the cookie (sequence number), the server can then establish the connection. This way, the server doesn't waste resources on connections that are never completed, as would be the case in a SYN flood attack.</p>
</li>
</ul>
</li>
</ul>
<h3 id="tcp-buffering"><a class="header" href="#tcp-buffering">TCP Buffering</a></h3>
<ol>
<li><strong>Send and Receive Buffers:</strong>
<ul>
<li><strong>Purpose:</strong> These buffers are used to temporarily store data before it is sent (send buffer) or after it is received (receive buffer) over a network connection.</li>
<li><strong>Location:</strong> They are associated with each socket, which is an endpoint for sending or receiving data in a network connection.</li>
</ul>
</li>
<li><strong>Tunable Buffer Sizes:</strong>
<ul>
<li><strong>Customization:</strong> The size of both send and receive buffers can be adjusted (tuned) to suit specific needs.</li>
<li><strong>Throughput vs. Memory Trade-off:</strong> Increasing the size of these buffers can improve data throughput (the rate at which data is successfully transferred over the network). However, larger buffer sizes also mean more of the computer's main memory (RAM) is used per connection.</li>
</ul>
</li>
<li><strong>Asymmetric Buffer Sizing:</strong>
<ul>
<li><strong>Adaptation to Server Role:</strong> One buffer can be made larger than the other, depending on the server’s expected usage. For instance, if a server is primarily sending data, the send buffer may be increased in size compared to the receive buffer, and vice versa.</li>
</ul>
</li>
<li><strong>Dynamic Buffer Sizing by the Linux Kernel:</strong>
<ul>
<li><strong>Automatic Adjustment:</strong> The Linux kernel can dynamically adjust the size of these buffers based on the activity of the connection.</li>
<li><strong>Tuning Parameters:</strong> The kernel allows for the tuning of buffer sizes, including setting minimum, default, and maximum sizes.</li>
</ul>
</li>
<li>the send and receive buffers for TCP sockets, which are mentioned in the context of improving data throughput, are different from the buffers shown in the output of the <code>free -h</code> command on Linux systems.
<ol>
<li><strong>TCP Send and Receive Buffers:</strong>
<ul>
<li>These buffers are specifically allocated for each TCP socket connection.</li>
<li>Their sizes determine how much data can be temporarily stored while being sent or received over that particular socket.</li>
<li>The sizes of these buffers can be tuned for performance optimization and are managed by the TCP stack within the kernel.</li>
</ul>
</li>
<li><strong>Buffers in <code>free -h</code> Command:</strong>
<ul>
<li>The <code>free -h</code> command in Linux displays the total amount of free and used physical and swap memory in the system, as well as the buffers and cache used by the kernel.</li>
<li>The &quot;buffers&quot; shown in <code>free -h</code> refers to memory used by the kernel to buffer block devices (like hard drives). This helps in speeding up access to disk data and is unrelated to network sockets.</li>
<li>These are general-purpose buffers used by the kernel for various system activities and are not directly related to the send and receive buffers of TCP sockets.</li>
</ul>
</li>
</ol>
</li>
</ol>
<h3 id="segmentation-offload-gso-and-tso"><a class="header" href="#segmentation-offload-gso-and-tso">Segmentation Offload: GSO and TSO</a></h3>
<ol>
<li>
<p><strong>Segmentation Offload:</strong></p>
<ul>
<li>
<p><strong>Purpose:</strong> This is a technique used to reduce the overhead of the network stack (the software that handles network communication) in an operating system.</p>
<p>To avoid the network stack overheads of sending many small packets Linux uses generic segmentation offload (GSO) .</p>
</li>
</ul>
</li>
<li>
<p><strong>Maximum Segment Size (MSS):</strong></p>
<ul>
<li><strong>Definition:</strong> MSS is the largest size of a packet or segment that can be sent in a TCP connection. For many networks, the MSS is typically around 1500 bytes, which is the standard Ethernet frame size.</li>
</ul>
</li>
<li>
<p><strong>Generic Segmentation Offload (GSO):</strong></p>
<ul>
<li><strong>Function:</strong> GSO allows the operating system to send large packets (up to 64 Kbytes, referred to as “super packets”) to the network device.</li>
<li><strong>Process:</strong> These super packets are then divided into smaller segments, each fitting within the MSS, just before they are delivered to the network device for transmission.</li>
</ul>
</li>
<li>
<p><strong>TCP Segmentation Offload (TSO):</strong></p>
<ul>
<li><strong>Integration with Network Interface Cards (NICs):</strong> When the NIC and its driver support TSO, the task of splitting the large packets into MSS-sized segments is offloaded to the NIC hardware.</li>
<li><strong>Advantage:</strong> This offloading significantly reduces the processing load on the server's CPU and improves the throughput of the network stack.</li>
</ul>
</li>
<li>
<p><strong>Generic Receive Offload (GRO):</strong></p>
<ul>
<li><strong>Complementary Technique to GSO:</strong> GRO is similar to GSO but works for incoming packets. It allows the system to process fewer, larger packets, which reduces CPU overhead.</li>
<li><strong>Implementation:</strong> Both GRO and GSO are implemented in the kernel software.</li>
</ul>
</li>
<li>
<p><strong>Implementation of TSO:</strong></p>
<ul>
<li><strong>Hardware-Based:</strong> TSO is implemented in the NIC hardware, differentiating it from GSO and GRO, which are software-based.</li>
</ul>
</li>
</ol>
<h3 id="queueing-discipline"><a class="header" href="#queueing-discipline">Queueing Discipline</a></h3>
<ol>
<li></li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="methodology-1"><a class="header" href="#methodology-1">Methodology</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="observability-tools-1"><a class="header" href="#observability-tools-1">Observability Tools</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="experimentation-1"><a class="header" href="#experimentation-1">Experimentation</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tuning-1"><a class="header" href="#tuning-1">Tuning</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="exercises-1"><a class="header" href="#exercises-1">Exercises</a></h1>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
