# Concepts

1. The following are a selection of important file system performance concepts.

## File System Latency

1. File system latency is the main indicator of file system performance, measuring the time from a logical file system request to its fulfillment.
2. It encompasses time spent within the file system and disk I/O subsystem, as well as waiting on disk devices (physical I/O).
3. Application threads often pause during a request to wait for file system actions to finish, meaning file system latency directly impacts application performance.
4. Exceptions where applications might not be directly affected include the use of non-blocking I/O, prefetching (Section 8.3.4), and when I/O is initiated from an asynchronous thread.
5. Historically, operating systems have not made file system latency easily visible, focusing more on disk device-level statistics.
6. But sometimes, these stats don't reflect how well apps are running.
7. For instance, file systems sometimes do background tasks like flushing data, causing spikes in disk activity.
8. This might look bad on disk stats, but it doesn't mean apps are waiting for it to finish.
5. Check Section 8.3.12 for more examples of this.

## Caching

1. The file system often uses main memory as a cache to speed up operations.
2. This means applications can access data faster because it's stored in memory rather than on slower disks.
3. As time goes on, the cache grows, reducing available memory for the operating system. But don't worry, this is normal.
4. The idea is: if there's spare memory, use it. When applications need more memory, the kernel should free some from the cache.
5. File systems use caching for reading and buffering for writing, which helps improve performance.
6. Different types of cache are used by both the file system and the block device subsystem.

| Cache                       | Example                     |
| --------------------------- | --------------------------- |
| Page cache                  | Operating system page cache |
| File system primary cache   | `ZFS ARC`                   |
| File system secondary cache | `ZFS L2ARC`                 |
| Directory cache             | dentry cache                |
| inode cache                 | inode cache                 |
| Device cache                | `ZFS vdev`                  |
| Block device cache          | Buffer cache                |



## Random vs. Sequential I/O

1. File system operations can be random or sequential, depending on where they happen in the file.
2. Sequential operations follow each other, starting where the previous one ended.
3. Random operations have no pattern; they occur anywhere in the file.
4. A random workload might involve accessing many different files in no particular order.
5. Due to certain storage devices' performance characteristics (see Chapter 9, Disks), file systems aim to minimize random I/O by arranging file data sequentially and contiguously on disk.
6. Fragmentation occurs when file systems fail to organize data effectively, causing files to be scattered across the drive and turning sequential logical I/O into random physical I/O.
7. File systems track logical I/O access patterns to identify sequential workloads and enhance performance through techniques like prefetching or read-ahead.
8. These performance-improving techniques are more beneficial for rotational disks compared to flash drives.

## Prefetch

1. A common file system workload involves sequentially reading a large amount of file data, such as during a file system backup.
2. This data may not fit in the cache or may only be read once, resulting in a low cache hit ratio.
3. **Prefetch** is a feature that addresses this issue by detecting sequential read patterns based on file I/O offsets.
4. It predicts and fetches data from disk before the application requests it, populating the cache.
5. If the application subsequently reads the prefetched data, it results in a cache hit, improving performance.
6. Example scenario:
    1. Application requests file read.
    2. Data not in cache, so file system reads from disk.
    3. If offsets are sequential, file system issues additional prefetch reads.
    4. Initial read completes, data passed to application.
    5. Prefetch reads complete, caching data for future reads.
    6. Subsequent application reads are faster from cached data in RAM.
7. Effective prefetching greatly improves sequential read performance by keeping disks ahead of application requests.
8. Poor prefetching, however, leads to unnecessary I/O, polluting the cache and consuming resources.
9. File systems usually allow prefetch settings to be adjusted for optimal performance.



## Read-Ahead

1. Historically, prefetch has also been known as read-ahead. Linux uses the read-ahead term for a system call, readahead(2), that allows applications to explicitly warm up the file system cache.

## Write-Back Caching

1. Write-back caching is commonly used by file systems to boost write performance.
2. It works by treating writes as complete once transferred to main memory, delaying disk writes until later, asynchronously.
3. This delayed writing process to disk is called flushing.
4. Example sequence:
    1. Application initiates a file write.
    2. Data is copied to kernel memory.
    3. Kernel signals completion to the application.
    4. Later, an asynchronous task writes the data to disk.
5. The trade-off is reliability; data stored in volatile main memory might be lost during power failures, or disk writes could be incomplete, leading to corruption.
6. If file system metadata becomes corrupted, the system may fail to load, requiring recovery from backups and causing downtime.
7. Corruption affecting file contents used by applications could jeopardize business operations.
8. To balance speed and reliability, file systems often use write-back caching by default but provide a synchronous write option for direct, immediate writes to persistent storage.

## Synchronous Writes

1. Synchronous writes ensure data is fully written to persistent storage, including necessary metadata changes, making them slower than asynchronous writes.
2. They are commonly used in applications like database log writers, where data corruption risk from asynchronous writes is unacceptable.
3. Two forms of synchronous writes exist:
    a. Individual I/O: File opened with flags like O_SYNC or variants, ensuring synchronous write.
    b. Groups of previous writes: Application synchronously commits previous asynchronous writes at checkpoints using fsync(2) system call, improving performance and avoiding multiple metadata updates.
4. Other situations triggering write commits include closing file handles or too many uncommitted buffers, which can cause noticeable delays, especially over NFS.
